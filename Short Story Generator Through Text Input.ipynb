{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d2b9fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in e:\\anaconda\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: aiohttp in e:\\anaconda\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.20 in e:\\anaconda\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in e:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\lib\\site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\anaconda\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\lib\\site-packages (from tqdm->openai) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1050a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the kind of story you want/ Starting lines of story \n",
      "Friends fighting in the rain\n",
      "\n",
      "Once upon a time, there were two best friends who had been through thick and thin over the years. Even though they had their differences, they had a deep bond of friendship and were always there for each other.\n",
      "\n",
      "One day, a heavy downpour began and the two friends decided to take a walk in the rain. As they were walking, they started arguing over a silly topic and their argument quickly escalated into a full-blown fight.\n",
      "\n",
      "The rain was pouring down and the two friends were screaming and shouting at each other. They pushed each other and threw punches and kicks. The fight went on for what seemed like hours, but eventually, one of them got tired and decided to give up.\n",
      "\n",
      "The other friend, however, was still filled with rage and refused to back down. He kept hitting his friend, until the other one finally broke down and started crying.\n",
      "\n",
      "It was then that the first friend finally realized what he had done and stopped. He hugged his friend and apologized for his actions. The other friend also realized his mistake and the two of them hugged and made up.\n",
      "\n",
      "The rain continued to pour down, but the two friends were no longer fighting. They had learned their lesson and were closer than ever before.\n",
      "The end.\n"
     ]
    }
   ],
   "source": [
    "import openai # To access the OpenAI GPT-3 language model. \n",
    "\n",
    "# Enter your API Key\n",
    "# Check the Read Me File\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Function to generate a story using OpenAI's model\n",
    "def short_story_generator(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003', # Using davinci model\n",
    "        prompt=prompt, # Given input\n",
    "        max_tokens=600, # Specifies the maximum number of tokens (words or characters) in the generated output.\n",
    "        n=1, # Specifies the number of alternative completions to generate. Here, it is set to 1, so only one story will be generated.\n",
    "        stop=None, # Indicating that the story generation should continue until the maximum number of tokens is reached.\n",
    "        temperature=0.7 # Controls the randomness of the generated output. A higher value (e.g., 0.7) leads to more diverse and creative results, while a lower value (e.g., 0.2) makes the output more focused and deterministic.\n",
    "    )\n",
    "    # Retrieving the generated text from the API response and removes any leading or trailing whitespace.\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Function to tell the story\n",
    "def tell_short_story():\n",
    "    prompt = input(\"Enter the kind of story you want/ Starting lines of story \\n\")\n",
    "    print()\n",
    "    story = short_story_generator(\"Give a story on \"+prompt)\n",
    "    # Printing the story\n",
    "    print(story)\n",
    "    print(\"The end.\")\n",
    "\n",
    "# Tell the story\n",
    "tell_short_story()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5746c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf4db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
